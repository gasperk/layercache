#summary Prefetching the data, before it times out

= Prefetching the data =

== The problem ==
When an item in the cache is too old, it gets removed. Likewise, if the cache is too small, some items are evicted prematurely, in order to make place for newer items. At that moment, all reads for such items will return null, and the data will be requested from the source (i.e. the database). The data will then be written to the caches, so it'll be available from there for subsequent reads.

But, if the number of requests for a certain item is high, several clients will detect a cache miss at the same time, and all of them will read the data from the source. For example, if there is 100 requests for an item per second, a few ten (up to a hundred in this example) identical queries will be issued to the database. This can put a lot of load on the database, especially if you consider that this could happen to several items at once.

Database's query cache can help you here, but not necessarily. MySQL cache, for example, has [http://www.mysqlperformanceblog.com/2006/07/27/mysql-query-cache/ a few problems].

So, how to avoid the database being slammed?

== The solution ==
The solution is simple and effective - prefetch. This means that an item will be prefetched _before_ its time is up, before it should be treated as stale. For prefetch, you can define two parameters: time and probability. Time defines how many seconds before an item is stale should prefetch be considered, and probability defines how probable is prefetch to happen within that time.

To explain by example with an item that has TTL 360 (5 minutes), and with prefetch set to 60 seconds with 0.01 probability. When the item in the cache is within the last 60 seconds of its lifetime, each request will decide whether or not should it go fetch the item. Probability 0.01 means 1 in 100, so this means only 1/100 requests will go fetch the item, others will continue reading the item from the cache. When the item is written back by that 1/100 requests, it's TTL will again be 360s, so no request will trigger prefetch for another 4 minutes.

This results in a much less requests to the source, i.e. the database. However, prefetch only solves the problem for items being "naturally evicted" (by being too old). Items that are prematurely evicted in order to make more space in the cache will still be slammed, because there is no way of detecting when a certain item will be evicted.

== An example ==
To enable prefetch, you have to specify it for each cache you add to a stack.
{{{
LayerCache::
  forSource(new SomeDataSource)->
  addCache(new LayerCache_Cache_Memcache($memcache))->withTTL(360)->withPrefetch(60, 0.01)->
  toStack('data');
}}}